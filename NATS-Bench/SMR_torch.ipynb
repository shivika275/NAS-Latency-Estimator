{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dstBZgrz_xYJ",
        "outputId": "d13e0301-69ca-47ba-be92-013c672e7921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nats_bench in /usr/local/lib/python3.10/dist-packages (1.8)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from nats_bench) (1.23.5)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.10/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "#Installing nats_bench\n",
        "!python3 -m pip install nats_bench\n",
        "!python3 -m pip install gputil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpGEixY5CyhV",
        "outputId": "e8ea73dc-df79-4a89-d350-425c62870d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AutoDL-Projects'...\n",
            "remote: Enumerating objects: 6232, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 6232 (delta 31), reused 87 (delta 27), pack-reused 6133\u001b[K\n",
            "Receiving objects: 100% (6232/6232), 11.24 MiB | 10.41 MiB/s, done.\n",
            "Resolving deltas: 100% (4386/4386), done.\n",
            "Updating files: 100% (457/457), done.\n",
            "/content/AutoDL-Projects\n",
            "Processing /content/AutoDL-Projects\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from xautodl==1.0.0) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from xautodl==1.0.0) (6.0.1)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.10/dist-packages (from xautodl==1.0.0) (0.1.5.post20221221)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fvcore->xautodl==1.0.0) (0.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->xautodl==1.0.0) (4.66.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->xautodl==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->xautodl==1.0.0) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->xautodl==1.0.0) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from fvcore->xautodl==1.0.0) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore->xautodl==1.0.0) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore->xautodl==1.0.0) (2.8.2)\n",
            "Building wheels for collected packages: xautodl\n",
            "  Building wheel for xautodl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xautodl: filename=xautodl-1.0.0-py3-none-any.whl size=225892 sha256=ba0d6ab388f1f12e7e47502cfae28bad86f1356bb8c9159e4ffbc299381d97b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/17/85/a4f85cb6a0cdf4223ebaf110795c95aea3177fd868bb6093c6\n",
            "Successfully built xautodl\n",
            "Installing collected packages: xautodl\n",
            "  Attempting uninstall: xautodl\n",
            "    Found existing installation: xautodl 1.0.0\n",
            "    Uninstalling xautodl-1.0.0:\n",
            "      Successfully uninstalled xautodl-1.0.0\n",
            "Successfully installed xautodl-1.0.0\n"
          ]
        }
      ],
      "source": [
        "#Installing AutoDL\n",
        "!git clone https://github.com/D-X-Y/AutoDL-Projects\n",
        "%cd /content/AutoDL-Projects/\n",
        "!python3 -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ntw5RWrDD1d7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from nats_bench import create\n",
        "from nats_bench.api_utils import time_string\n",
        "import numpy as np\n",
        "import torch\n",
        "import xautodl\n",
        "from xautodl.models import get_cell_based_tiny_net\n",
        "from xautodl.utils import count_parameters_in_MB\n",
        "import platform\n",
        "import GPUtil\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sFG-g9qD206",
        "outputId": "780ad4c7-ac09-467e-8c55-45d2529b5752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "AutoDL-Projects\t\t\t NATS-sss-v1_0-50262-simple.tar   NATS-tss-v1_0-3ffb9-simple.tar\n",
            "cifar.python\t\t\t NATS-tss-v1_0-3ffb9.pickle.pbz2\n",
            "NATS-sss-v1_0-50262.pickle.pbz2  NATS-tss-v1_0-3ffb9-simple\n",
            "/content/gdrive/.shortcut-targets-by-id/1m_5Kr7rURbHKXCurFDFRHAUYTXc8MVsc/SMR-Project\n",
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/SMR-Project/results’: File exists\n",
            "/content/gdrive/.shortcut-targets-by-id/1m_5Kr7rURbHKXCurFDFRHAUYTXc8MVsc/SMR-Project/NATS-Bench-1\n"
          ]
        }
      ],
      "source": [
        "#Mounting drive location for NATS-Bench files\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "!ls /content/gdrive/MyDrive/SMR-Project/NATS-Bench-1/\n",
        "%cd /content/gdrive/MyDrive/SMR-Project\n",
        "!mkdir /content/gdrive/MyDrive/SMR-Project/results\n",
        "%cd NATS-Bench-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YErUrnNqFSpM",
        "outputId": "94487afe-1609-486f-9bde-0457169ab84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!cp -r NATS-tss-v1_0-3ffb9-simple /root/.torch\n",
        "# !cp -r NATS-sss-v1_0-50262-simple /root/.torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api = create('NATS-tss-v1_0-3ffb9-simple', 'tss', fast_mode=True, verbose=True)\n",
        "print(len(api.meta_archs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7_-gyCHfJwi",
        "outputId": "bbcfdb77-0205-4688-f0e9-56a10a01faca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-15 02:44:56] Try to create the NATS-Bench (topology) api from NATS-tss-v1_0-3ffb9-simple with fast_mode=True\n",
            "[2023-10-15 02:44:56] Create NATS-Bench (topology) done with 0/15625 architectures avaliable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cuda_time() -> float:\n",
        "    torch.cuda.synchronize()\n",
        "    return time.perf_counter()\n",
        "@torch.inference_mode()\n",
        "def measure(model, img_size, num_repeats=500, num_warmup=500):\n",
        "    # model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    # backbone = model.backbone\n",
        "    inputs = torch.randn(4, 3, img_size, img_size).cuda()\n",
        "\n",
        "    latencies = []\n",
        "    for k in range(num_repeats + num_warmup):\n",
        "        start = cuda_time()\n",
        "        model(inputs)\n",
        "        if k >= num_warmup:\n",
        "            latencies.append((cuda_time() - start) * 1000)\n",
        "\n",
        "    #latencies = itertools.chain(dist.allgather(latencies))\n",
        "    latencies = sorted(latencies)\n",
        "\n",
        "    drop = int(len(latencies) * 0.25)\n",
        "    return np.mean(latencies[drop:-drop])"
      ],
      "metadata": {
        "id": "adi7bQvo-z1V"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def latency(api_main,i,dataset='cifar10'):\n",
        "  config = api.get_net_config(i, dataset)\n",
        "  network = get_cell_based_tiny_net(config)\n",
        "  info = api.get_more_info(i, dataset)\n",
        "  cost = api.get_cost_info(i,dataset)\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  network = network.to(device)\n",
        "  if(dataset == 'ImageNet16-120'):\n",
        "    img_size = 256\n",
        "  else:\n",
        "    img_size = 32\n",
        "  latency = measure(network,img_size)\n",
        "  data=[config['name'],config['C'],config['N'],config['arch_str'],info['test-accuracy'],info['test-all-time'],info['test-per-time'],info['train-accuracy'],info['train-all-time'],info['train-per-time'],cost['flops'],cost['latency'], cost['params'],cost['T-ori-test@epoch'], cost['T-ori-test@total'], cost['T-train@epoch'], cost['T-train@total'], latency]\n",
        "  return data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "naeXZhqvFAMH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0A7GMu__9Uw",
        "outputId": "c8879587-41e1-4225-934e-4e6e6f1e7a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-15 03:00:55] Call the get_net_config function with index=0, dataset=cifar10.\n",
            "[2023-10-15 03:00:55] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:00:55] Call the get_more_info function with index=0, dataset=cifar10, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:00:55] Call query_index_by_arch with arch=0\n",
            "[2023-10-15 03:00:55] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:00:55] Call the get_cost_info function with index=0, dataset=cifar10, and hp=12.\n",
            "[2023-10-15 03:00:55] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=0, hp=12\n",
            "[2023-10-15 03:00:55] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:01] Call the get_net_config function with index=0, dataset=cifar100.\n",
            "[2023-10-15 03:01:01] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:01] Call the get_more_info function with index=0, dataset=cifar100, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:01:01] Call query_index_by_arch with arch=0\n",
            "[2023-10-15 03:01:01] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:01] Call the get_cost_info function with index=0, dataset=cifar100, and hp=12.\n",
            "[2023-10-15 03:01:01] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=0, hp=12\n",
            "[2023-10-15 03:01:01] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:08] Call the get_net_config function with index=0, dataset=ImageNet16-120.\n",
            "[2023-10-15 03:01:08] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:08] Call the get_more_info function with index=0, dataset=ImageNet16-120, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:01:08] Call query_index_by_arch with arch=0\n",
            "[2023-10-15 03:01:08] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:08] Call the get_cost_info function with index=0, dataset=ImageNet16-120, and hp=12.\n",
            "[2023-10-15 03:01:08] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=0, hp=12\n",
            "[2023-10-15 03:01:08] Call _prepare_info with index=0 skip because it is in arch2infos_dict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 1/4 [00:35<01:47, 35.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-15 03:01:31] Call the get_net_config function with index=1, dataset=cifar10.\n",
            "[2023-10-15 03:01:31] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:31] Call the get_more_info function with index=1, dataset=cifar10, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:01:31] Call query_index_by_arch with arch=1\n",
            "[2023-10-15 03:01:31] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:31] Call the get_cost_info function with index=1, dataset=cifar10, and hp=12.\n",
            "[2023-10-15 03:01:31] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=1, hp=12\n",
            "[2023-10-15 03:01:31] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:38] Call the get_net_config function with index=1, dataset=cifar100.\n",
            "[2023-10-15 03:01:38] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:38] Call the get_more_info function with index=1, dataset=cifar100, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:01:38] Call query_index_by_arch with arch=1\n",
            "[2023-10-15 03:01:38] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:38] Call the get_cost_info function with index=1, dataset=cifar100, and hp=12.\n",
            "[2023-10-15 03:01:38] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=1, hp=12\n",
            "[2023-10-15 03:01:38] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:48] Call the get_net_config function with index=1, dataset=ImageNet16-120.\n",
            "[2023-10-15 03:01:48] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:48] Call the get_more_info function with index=1, dataset=ImageNet16-120, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:01:48] Call query_index_by_arch with arch=1\n",
            "[2023-10-15 03:01:48] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:01:48] Call the get_cost_info function with index=1, dataset=ImageNet16-120, and hp=12.\n",
            "[2023-10-15 03:01:48] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=1, hp=12\n",
            "[2023-10-15 03:01:48] Call _prepare_info with index=1 skip because it is in arch2infos_dict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 2/4 [01:29<01:33, 46.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-15 03:02:25] Call the get_net_config function with index=2, dataset=cifar10.\n",
            "[2023-10-15 03:02:25] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:25] Call the get_more_info function with index=2, dataset=cifar10, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:02:25] Call query_index_by_arch with arch=2\n",
            "[2023-10-15 03:02:25] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:25] Call the get_cost_info function with index=2, dataset=cifar10, and hp=12.\n",
            "[2023-10-15 03:02:25] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=2, hp=12\n",
            "[2023-10-15 03:02:25] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:32] Call the get_net_config function with index=2, dataset=cifar100.\n",
            "[2023-10-15 03:02:32] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:32] Call the get_more_info function with index=2, dataset=cifar100, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:02:32] Call query_index_by_arch with arch=2\n",
            "[2023-10-15 03:02:32] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:32] Call the get_cost_info function with index=2, dataset=cifar100, and hp=12.\n",
            "[2023-10-15 03:02:32] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=2, hp=12\n",
            "[2023-10-15 03:02:32] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:39] Call the get_net_config function with index=2, dataset=ImageNet16-120.\n",
            "[2023-10-15 03:02:39] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:39] Call the get_more_info function with index=2, dataset=ImageNet16-120, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:02:39] Call query_index_by_arch with arch=2\n",
            "[2023-10-15 03:02:39] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:02:39] Call the get_cost_info function with index=2, dataset=ImageNet16-120, and hp=12.\n",
            "[2023-10-15 03:02:39] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=2, hp=12\n",
            "[2023-10-15 03:02:39] Call _prepare_info with index=2 skip because it is in arch2infos_dict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 3/4 [02:24<00:50, 50.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-15 03:03:19] Call the get_net_config function with index=3, dataset=cifar10.\n",
            "[2023-10-15 03:03:19] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:19] Call the get_more_info function with index=3, dataset=cifar10, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:03:19] Call query_index_by_arch with arch=3\n",
            "[2023-10-15 03:03:19] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:19] Call the get_cost_info function with index=3, dataset=cifar10, and hp=12.\n",
            "[2023-10-15 03:03:19] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=3, hp=12\n",
            "[2023-10-15 03:03:19] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:23] Call the get_net_config function with index=3, dataset=cifar100.\n",
            "[2023-10-15 03:03:23] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:23] Call the get_more_info function with index=3, dataset=cifar100, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:03:23] Call query_index_by_arch with arch=3\n",
            "[2023-10-15 03:03:23] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:23] Call the get_cost_info function with index=3, dataset=cifar100, and hp=12.\n",
            "[2023-10-15 03:03:23] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=3, hp=12\n",
            "[2023-10-15 03:03:23] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:26] Call the get_net_config function with index=3, dataset=ImageNet16-120.\n",
            "[2023-10-15 03:03:26] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:26] Call the get_more_info function with index=3, dataset=ImageNet16-120, iepoch=None, hp=12, and is_random=True.\n",
            "[2023-10-15 03:03:26] Call query_index_by_arch with arch=3\n",
            "[2023-10-15 03:03:26] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "[2023-10-15 03:03:26] Call the get_cost_info function with index=3, dataset=ImageNet16-120, and hp=12.\n",
            "[2023-10-15 03:03:26] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n",
            "Call query_meta_info_by_index with arch_index=3, hp=12\n",
            "[2023-10-15 03:03:26] Call _prepare_info with index=3 skip because it is in arch2infos_dict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [02:49<00:00, 42.47s/it]\n"
          ]
        }
      ],
      "source": [
        "# Create the API for size search space\n",
        "root_dir = '/content/gdrive/MyDrive/SMR-Project/results'\n",
        "if torch.cuda.is_available():\n",
        "  hw = str(GPUtil.getGPUs()[0].name)\n",
        "else:\n",
        "  uname = platform.uname()\n",
        "  hw = str(uname.machine) +'_'+str(uname.processor)\n",
        "if(not(os.path.exists(os.path.join(root_dir,hw)))):\n",
        "  os.makedirs(os.path.join(root_dir,hw))\n",
        "\n",
        "latency_cifar10 = []\n",
        "latency_cifar100 = []\n",
        "latency_imagenet = []\n",
        "\n",
        "total_models = len(api.meta_archs)\n",
        "# total_models = 4\n",
        "for i in tqdm(range(total_models),total=total_models):\n",
        "  latency_cifar10.append(latency(api,i,'cifar10'))\n",
        "  latency_cifar100.append(latency(api,i,'cifar100'))\n",
        "  latency_imagenet.append(latency(api,i,'ImageNet16-120'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_cols = ['model', 'C','N','arch_str','test-acc','test-all-time','test-per-time','train-acc','train-all-time','train-per-time','flops','latency-gen','params','T-ori-test@epoch','T-ori-test@total','T-train@epoch','T-train@total','latency']\n",
        "df_cifar10 = pd.DataFrame(latency_cifar10,  columns=all_cols)\n",
        "df_cifar100 = pd.DataFrame(latency_cifar100,  columns=all_cols)\n",
        "df_imagenet = pd.DataFrame(latency_imagenet,  columns=all_cols)"
      ],
      "metadata": {
        "id": "myPV3mmDNtdT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cifar10.to_csv(os.path.join(root_dir,hw,'cifar10.csv'))\n",
        "df_cifar100.to_csv(os.path.join(root_dir,hw,'cifar100.csv'))\n",
        "df_imagenet.to_csv(os.path.join(root_dir,hw,'imagenet16.csv'))"
      ],
      "metadata": {
        "id": "TKA9ADpnV7XJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VKCDW0z3c_5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}